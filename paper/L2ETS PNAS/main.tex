\documentclass[9pt,twocolumn,twoside,lineno]{pnas-new}
% Use the lineno option to display guide line numbers if required.
% https://www.pnas.org/authors/submitting-your-manuscript
\templatetype{pnasresearcharticle} % Choose template 
% {pnasresearcharticle} = Template for a two-column research article
% {pnasmathematics} %= Template for a one-column mathematics article
% {pnasinvited} %= Template for a PNAS invited submission

\title{Local similarity and global variability characterize the semantic space of human languages}

% Use letters for affiliations, numbers to show equal authorship (if applicable) and to indicate the corresponding author
\author[a,1]{Molly Lewis}
\author[b]{Aoife Cahill} 
\author[b]{Nitin Madnani}
\author[c,d,1]{James Evans}

\affil[a]{Carnegie Mellon University}
\affil[b]{Educational Testing Service}
\affil[c]{University of Chicago}
\affil[d]{Santa Fe Institute}

% Please give the surname of the lead author for the running footer
\leadauthor{Lewis} 

\significancestatement{The degree to which meanings align across the world’s languages suggests the limits of translation and cross-cultural communication, but remains contested. Approaching this question demands a systems-level view to compare the structure of meanings across many languages. Using machine learning we construct word embeddings -- dense, continuous, high-dimensional spaces that characterize word meanings from context -- across large samples of multi-lingual text. With these representations, we discover that (1) meanings across languages are similar within semantic domains and variable across them, and that (2) concrete meanings are less variable across languages than abstract ones, but all vary with distance. This suggests that associations and analogies, which interlink meanings within language, propose predictably different intuitions across distinct languages and confound transmission of complex ideas.}

% Please include corresponding author, author contribution and author declaration information
\authorcontributions{JE and ML designed the research; ML analyzed all data; AC and NM ran the TOEFL models. ML and JE wrote the manuscript.}
\authordeclaration{Please declare any competing interests here.}

\correspondingauthor{\textsuperscript{1}To whom correspondence should be addressed. E-mail: mollylewis@cmu.edu \& \\ jevans@uchicago.edu}

% At least three keywords are required at submission. Please provide three to five keywords, separated by the pipe symbol
\keywords{human cognition $|$ language $|$ semantics} 

\begin{abstract}
How does meaning vary across the world’s languages? Some claim word meanings are universal, while others exploring specific domains such as color and kinship have demonstrated variability. The emergence of word embedding models enables a systems-level approach that resolves this debate through direct comparison of word organization across semantic domains. Here we show that meanings across languages are characterized by similarity within semantic domains and variability across them, using models trained on both (1) large corpora of native language text comprising Wikipedia articles in 35 languages and also (2) English TOEFL essays written by 38,500 speakers from the same distinct native languages, which cluster into semantic domains. Consistent with universalist claims, concrete meanings are less variable across languages than abstract meanings, but consistent with relativist claims, all meanings vary with geographical, environmental and cultural distance. By simultaneously examining local similarity and global difference, we harmonize these claims and provide the first description of general principles that govern variability in semantic space across languages. The global structure of a speaker’s semantic space influences the comparisons cognitively salient to people who natively speak different languages, and suggests that even successful bilingual communicators likely think along global semantic associations from their native language while writing English. These findings have dramatic implications for language education, cross-cultural communication, and literal translations, which are impossible not because the objects of reference are uncertain, but because associations, metaphors and narratives interlink meanings differently in one language than another.
\end{abstract}

\dates{This manuscript was compiled on \today}
\doi{\url{www.pnas.org/cgi/doi/10.1073/pnas.XXXXXXXXXX}}

\begin{document}

\maketitle
\thispagestyle{firststyle}
\ifthenelse{\boolean{shortarticle}}{\ifthenelse{\boolean{singlecolumn}}{\abscontentformatted}{\abscontent}}{}

% If your first paragraph (i.e. with the \dropcap) contains a list environment (quote, quotation, theorem, definition, enumerate, itemize...), the line after the list may have some extra indentation. If this is the case, add \parshape=0 to the end of the list environment.
\dropcap{T}he answer to questions about the complex relationship between meaning and language strikes to the heart of a fundamental question in the social and communication sciences -- are word meanings universal or variable across the world's languages? What precisely is the relationship between the meaning of words ``bell'', ``smell” and ``hell'' in English and their closest translations in Persian or Russian? An emerging body of data collected by anthropologists documents substantial variability across languages regarding their semantic organization within some specific domains, such as color \cite{berlin1991basic} and kinship \cite{murdock1970kin}. On the other hand, there is evidence that in cases of shared, concrete experiences, there is a high degree of semantic similarity across languages \cite{youn2016universal}.
%wierzbicka1996semantics - includes abstract and concrete meanings

Understanding the nature and degree of cross-linguistic semantic variability is important because it holds cognitive implications for our ability to learn and switch between languages, just as it pinpoints the pitfalls and potential of intercultural communication around the world. To the extent that language meanings are universal \cite{wierzbicka1996semantics,fodor1975language}, the process of learning a language or translating a document is simply the process of mapping linguistic forms to the same units of meaning. In contrast, to the extent that languages vary in their underlying meaning systems, the process of learning a language or translating an idea requires not only learning new word forms but also acquiring a rich representation of that system. These two possibilities have very different implications for the tasks of language learning, communicating, translating and even reasoning in different contexts. Most notably, if languages vary in their meanings, it is possible that speakers of different languages think in different ways. This provocative possibility has lead to a long-standing debate centered around case studies of particular semantic domains and languages \cite{winawer2007russian,gennari2002motion,brown1993uphill}.

Here, we describe and explore semantic variability by examining semantic relationships for distinct languages \textit{across} referential domains, rather than within a single domain. By taking this ``system-level'' approach \cite{saussure, levi2008structural}, we are able to identify domains of relatively greater semantic variability and similarity across languages. More importantly, however, this system-level approach allows us to characterize the macro {\it structure} of variability in the organization of global meanings. We find that variability in the structure of semantic space across languages is characterized by a high degree of similarity within semantic domains, but significantly more difference in the relationships between those domains. This identifies dramatic differences in the set of cross-domain semantic associations, metaphors and similes that speakers from distinct languages have cognitively available to them. 

Examining lexical semantics at the system level presents several methodological challenges. Classic work on cross-linguistic semantics has explored the relationship between words within a single \cite{berlin1991basic,regier2007color,baddeley2009} or a few \cite{thompson2020cultural} semantic domains. Researchers have pursued this approach in part because it is unclear how to compare diverse meanings: Red and pink can be compared along dimensions of lightness or saturation, but how does one compare the meaning of red to the meaning of mother? And yet the relative position of diverse meanings condition the space of cognitively available associations. The domain-centric approach is further limited by its requirement that the analyst define relevant semantic domains of inquiry, thereby imposing idiosyncratic structure and the potential for bias.

Here we address these challenges by taking advantage of a recent advance in machine learning: neural network approaches to word embeddings \cite{bojanowski2016enriching,mikolov2013efficient}. Word embeddings provide a system-level description of semantics derived from the complex distribution of word collocations in a corpus of text. In the word embedding framework, each word is represented as a high dimensional (e.g., 200) vector, and distance between vectors corresponds to similarity between words, with closer words indicating more similar meanings. Word embeddings have been shown to be highly correlated with human judgments of semantic similarity and to encapsulate and represent culture-specific biases with fidelity \cite{hill2015simlex,caliskan2017semantics,garg2018word,bolukbasi2016man,kozlowski2019geometry,lewis2020}. We describe computed word embeddings as representing the semantic space of a language and explore semantic distance between pairs of languages in this space by evaluating continuous distances between word pairs in both. We then cluster words based on their loadings on embedding dimensions to compare ``local'' (within cluster) versus ``global'' (across cluster) variability in semantics between languages. We note that this distinction between local and global refers only to semantic distances within languages, synonymous with meanings that cluster versus those that span the language, and has no relationship to geographical, environmental or cultural distance. A positive correlation in word distances between two languages suggests that the two languages similar relationships between lexical meanings, which we take as evidence for semantic similarity between those languages.

%expand on these in our methods section.

Using word embeddings, we compare the structure of semantic space for 35 different languages that span 11 language families in two stages with two distinct datasets. First, we examine the direct relationship between concrete and abstract words, and between local and global word distances in the context of a large, naturalistic corpus of native language text, an embedding of all Wikipedia entries produced within each language. In Supplementary Figure S1, we show that for the 35 languages we examine, engagement with Wikipedia is comparable in terms of article production and consumption.

Second, we seek to validate these patterns, controlling for differences in topic, lexicon, and syntax, by analyzing TOEFL essays written in English by second language learners from the corresponding languages. This allows us to examine the semantics of different languages without assuming translation equivalents of word meanings, and while holding constant native language grammar and lexicon. It also allows us to control for broad topic, as all essays are written in response to the same prompts. The striking similarity of patterns between findings from these two datasets confirm that the semantics of one's native language influences the semantics of one's second language for bilingual speakers \cite{ameel2009semantic}, such that language learners from Athens ``think Greek'' while writing English. 

Together these two datasets provide converging evidence about the structure of meaning across human languages. We find substantial variability across languages in the structure of semantic space, but that the relationship between the semantic systems of different languages is principled. Languages spoken by speakers culturally and geographically more similar manifest comparably similar semantic spaces. Furthermore, we find that the {\it ways} in which languages differ from each other is principled: Languages tend to vary much more across semantic domains than within them. 





%1. Validating the data: ETS & Wikipedia capturing the same cross language variation (1+)

%We trained word embedding models on text written by native speakers of 35 different languages, across 11 different language families, and compared these models to models trained on native language text. Essays written by speakers of the same language were much closer to essays written by speakers of the same native language, suggesting that models trained on second-language text were capturing native language semantics.

\section*{Semantic difference between languages}
%\paragraph*
To evaluate the overall semantic differences between languages, we examined the position of TOEFL essays in an embedding space as a function of the native language of the essay writer. We quantified semantic distinctiveness at the language level by taking the difference between mean pairwise cosine distances for essays written by speakers of a particular native language, relative to distances between essays written by different native language speakers. This value was substantially greater than zero for all languages in our sample ($M$ = 0.018, $SD$ = 0.007; $t$(34) = 16.35, $p$ $<$ .00001), suggesting that each language was associated with a distinct semantic space. This difference was also observed in a non-parametric analysis  ($W$ = 630, $p$ $<$ .00001). Furthermore, low scoring essays ($M$ = 0.02, $SD$ = 0.006) were more distinct than high scoring essays ($M$ = 0.016, $SD$ = 0.007; $t$(34) = 3.91, $p$ $<$ .001; $W$ = 517, $p$ $<$ .001; see Fig.\ S2), suggesting that as learners become more skilled in English, their English semantics diverge from those in their native languages. Nevertheless, high-scoring essays continue to display semantic associations from the native language, and differences were not attributable to English grammatical or syntactical errors (see Fig.\ S3a). 


%2. Concrete similarity - Universalists
\section*{Concrete concepts translate better than abstract ones}
Having validated second-language text as a method for analyzing cross-linguistic semantic variability, we next examined cross-linguistic similarity in the structure of semantic space. Universalists argue that all languages share roughly the same semantic structure, while relativists argue for substantial variability.

We hypothesized that the {\it amount} of variability for a particular semantic domain across languages would vary, but in a principled manner. We reasoned that semantic domains referring to meanings that were more \textit{perceptually} available and concrete such as ``food'' and ``body'' would be more similar across languages, relative to domains more conceptual and abstract like ``injustice'' and ``democracy''. This hypothesis is motivated by the idea that, while there is substantial variability in the cultures and environments in which languages are spoken, all speakers share roughly the same perceptual systems and would therefore be more likely to experience similar concrete objects in similar ways.

To test this hypothesis, we estimated the concreteness of each word based on human judgments, and partitioned them into 10 contiguous sets separated by rising concreteness thresholds  \cite{brysbaert2014concreteness}. These sets overlapped strongly and significantly with semantic clusters in both the TOEFL ($\chi^2$(81) = 1538.1; $p$ $<$ .00001) and Wikipedia word samples ($\chi^2$(81) =  5144.1; $p$ $<$ .00001; Fig.\ 1a), far above what one would expect from a random distribution of concreteness over clusters. In line with universalist claims, languages exhibit higher similarity in more perceptually concrete domains, and less in those more conceptually abstract (TOEFL: $r$ = .78; $p$ $=$ .008; Wikipedia: $r$ = .82; $p$ $=$ .004; Fig.\ 1b; see  Figs.\ S4-S5 for supporting analyses).

These results contrast with the findings of Thompson, et al. \cite{thompson2020cultural} who find no relationship between the concreteness of word meanings and cross-linguistic semantic alignment using word embedding models. This distinction follows from their approach to sampling words and relationships, compared with our system-level approach. We examined a large set of words (10,000) sampled randomly across the entire semantic space, rather than words hand-picked from a small list of semantic domains ({\it N} = 21). Further, our method for comparing word similarity cross-linguistically evaluates the relations between all words across semantic space, semantically near and far ($5\times10^7$), whereas their work only evaluated the 100 nearest-neighbors to target words. When we replicated their analysis, their described measurement, we find a small negative relationship between concreteness and semantic alignment, which grows much larger and strongly significant when our much larger collection of words and complete comparisons are considered.   

\section*{Environment and culture predict semantic deviations}
Even within highly concrete domains, however, we observed appreciable variability in the structure of semantic space across languages. We estimated pairwise-distances between the 22 primitive words examined by Youn et al. in their demonstration of a supposedly ``universal'' structure of lexical semantics (2016; e.g. ``water'', ``sun'', ``dirt'') and still found moderate variability in pairwise-distances across languages. 

This variability, however, was highly predictable by physical and environmental distances. Languages in closer physical distance exhibit \textit{much} more similar semantic representations for almost all of these highly concrete words (QAP $p$ $<$ .01: physical: 20/22; Fig.\ 1c;  Fig.\ S6) and environmental distance explains variations for some of the items (environmental: 6/22). This suggests that even for concrete meanings, there is variability in the structure of semantics across languages and this variability is predictable by a combination of differences in the perceptual experience of those language speakers and the potential for direct or indirect cultural contact.  



% Fig 1
\begin{figure*}[t!]
\centering
\includegraphics[width=15cm]{figs/fig1.png}
\caption{{\textbf A.} Distribution of words in each semantic cluster across concreteness deciles based on word embeddings obtained from Second-Language TOEFL Corpus and  Multilingual Wikipedia Corpus. {\textbf B.} Mean cross-linguistic word distance correlation (Pearson's $r$) as a function of the concreteness decile of the words. Larger values indicate more semantic similarity across languages. Point shape indicates corpus.  Point ranges correspond to bootstrapped 95\% confidence intervals; Range on model fit corresponds to the standard error. {\textbf C.} Linear model fits for cross-linguistic word distance correlation (Pearson's $r$) as a function of the geodesic distance between two languages (meters). Each data point corresponds to a unique language-pair-word combination. The colored lines correspond to the model fit for each word, and the black line shows the overall model fit and the corresponding standard error.}
\label{fig:fig1} 
\end{figure*}




%3. Cultural variation - Relativists
Next, we seek to explain the similarity of semantic structure for the entire lexicon across languages as a function of similarity between language contexts. Many dimensions of similarity exercise independent significant influences. These include geographical and environmental similarity, phonological and grammatical similarity, and cultural similarity comprising factors ranging from likeness in the structure of kinship, religion, politics and social class (Fig.\ 2; Table S1; Fig.\ S7). Contradicting claims of universal semantics, these analyses suggest that language semantics vary across languages, but remain predictable by cultural difference and environmental distance. 

% FIG 2
\begin{figure*}[t!]
\centering
\includegraphics[width=16.7cm]{figs/fig2.png}
\caption{{\textbf A.} Two-dimensional projection of language centroids calculated from  document embeddings of the Second Language TOEFL Corpus. Color corresponds to language family. {\textbf B.} Hierarchical clustering of languages based on pairwise language distances of language centroids.; {\textbf C.} Standardized linear estimates of semantic distance predictors. Ranges are 95\% confidence intervals. Red points indicate estimates from single-predictor model; grey points indicate estimates from additive linear model with all five predictors included.}.
\label{fig:fig2} 
\end{figure*}



%4. Local similarity / global distance
\section*{Local similarity and global variability in semantic space}
These analyses motivate us to examine how languages vary in their structure at the ``system'' level across semantic domains. Across the semantic system, word meanings may differ in terms of their {\it local} semantic relations within a semantic domain -- e.g., the relative similarity of meanings associated with ``earth'' and ``sun'' (Fig.\ 3). Alternatively, meanings may differ in terms of their {\it global} semantic relationships across semantic domains -- e.g. the relative similarity of the ``astronomy'' cluster of meanings (``earth,'' ``sun,'' etc.) to the ``religion'' cluster (``spirit,'' ``hell,'' etc.). Finally, meanings may differ evenly across the system. We first found that word pairs from the same concreteness decile (``local'' relations) were more similar to each other across languages, relative to word pairs across concreteness deciles (``global'' relations; TOEFL:  $M$  $=$ 0.025, $SD$ $=$  0.005; $t$(594) $=$ 128.64; $p$ $<$ .0001; $d$ = 1.28 [1.15, 1.4];  $W$ = 177310, $p$ $<$ .0001; Wikipedia: $M$  $=$ 0.035, $SD$  $=$  0.015; $t$(594) $=$ 56.88; $p$ $<$ .0001;  $d$ = 0.27 [0.16, 0.39];  $W$ = 177272, $p$ $<$ .0001). To more directly measure local-global semantic relations, which are not exclusively organized by concreteness, we examined the relative contribution of these two types of variability for word groups defined by semantic clusters (see Methods for detail). Critically, we found that local semantic clusters were much more correlated across languages, relative to global semantic structure, and demonstrated stronger differences than between concreteness deciles in both the TOEFL ($M$  $=$ 0.058, $SD$ $=$  0.008;  $t$(594) = 185.97; $p$ $<$ .0001; $d$ = 2.84 [2.68, 3]; $W$ = 177310, $p$ $<$ .0001) and Wikipedia datasets ($M$  $=$ 0.038, $SD$  $=$  0.024; $t$(594) = 38.27; $p$ $<$ .0001;  $d$ = 0.31 [0.19, 0.42]; $W$ = 174402, $p$ $<$ .0001;  Figs.\ 4a-5; Figs.\ S8-S9). This effect was not related to the grammatical similarity of the languages (Fig. S3B), and grew substantially larger as the number of semantic clusters increased (Fig. 3B). 

% FIG 3
\begin{figure*}[t!]
\centering
\includegraphics[width=16cm]{figs/Fig3.png}
\caption{{\textbf A.} Schematic representation of local and global distances in word embedding models. The figure shows three ``clusters'' of meanings and the relationships between them. Local relationships are within-cluster distances; global relationships are between-cluster distances. Some clusters are closer globally (e.g., $C_{music}$ and $C_{religion}$) than others (e.g., $C_{music}$ and $C_{war}$). {\textbf B.} Schema of the structure of cross-linguistic variability in local and global semantic structure. Each shading corresponds to a language. Languages tend to have overlapping clusters--to share local similarity--but vary in their global relations (e.g.  $C_{1}$ and $C_{2}$ are globally close in Language A, but not in Language B). {\textbf C.} Cross-linguistic word distance correlations for word groups in 10 semantic clusters based on words embeddings obtained from Second-Language TOEFL Corpus (top) and Multilingual Wikipedia Corpus (bottom). Red points indicate mean local correlation for each cluster, and blue squares indicate global correlation for each cluster.  {\textbf D.} Cross-linguistic word distance correlations for local versus global semantic comparison as a function of the number of semantic clusters. Point ranges correspond to 95\% confidence intervals.}
\label{fig:localglobal} 
\end{figure*}



% FIG 4
\begin{figure*}[t!]
\centering
\includegraphics[width=16.7cm]{figs/Fig4.png}
\caption{Semantic cluster graphs where links between clusters represent whether or not those clusters are within the top quartile of global semantic closeness for the proportion of languages that share both clusters specified above each graph. Links between clusters in Panel A are shared by almost all (0.9-1.0] languages in which the clusters manifest. Panels B-D represent global associations shared among fewer languages (0.5-0.9], (0.25-0.5], and (0.0-0.25]. These differences illustrate that despite stable, shared local semantic clusters across languages, global associations between those clusters vary dramatically. All graphs are rendered in 2D using force-directed algorithms that draw together the most connected clusters. See more details about data, cluster labels, and 2D layout in the Supplementary Materials.}
\label{fig:fig4} 
\end{figure*}


\section*{Implications for language learning and cross-cultural communication}
%\paragraph*
By taking a system-level view, these findings highlight limitations to binary characterization of the world's languages by semantic universality or semantic relativity. Consistent with semantic universalists who demonstrate semantic similarity between concrete, ``natural'' concepts, we show that the configuration of concrete concepts in semantic space is much more likely to be conserved across languages than abstract concepts such as democracy, tragedy, or spiritual agents like angels and demons. Consistent with semantic relativists, we show that the distance between concepts in semantic space is a function of lexical and grammatical distance between the languages, and the cultural and physical distance between the peoples and place where they are spoken. Neither semantic universalism nor relativism, however, characterizes the most significant, overarching pattern of similarity and difference across languages. Languages tend to be locally similar and globally varied: they are similar in how they cluster words with meanings proximate to one another, but divergent in how those clusters relate across the entire semantic space. Words associated with foods, body parts, spiritual agents, and tragedies individually tended to cluster together, but relations between them varied widely by language. 

The global structure of a speaker's semantic space necessarily influences the comparisons and metaphors cognitively salient to people who natively speak different languages: People who ``think'' in Greek cognitively follow and produce distinct semantic associations in text from others who ``think'' in Arabic, Farsi, Igbo or Chinese. This variability has powerful practical implications for language learning -- it suggests that learning words in a new language is not just a process of learning word forms and their mappings to referents, but also the higher-order association between their meanings. Currently, second-language training begins with explicitly translated word associations, often clustered locally within domains of experience (e.g., words for objects found in a house), interleaved with grammatical patterns required to use those words correctly in sentences. Later, language learners are introduced to global associations between clusters of meaning implicitly through native language literature and traditional stories. When people from a language write about family, do they also tend to link it with concepts of immutable stones and mountains, health, tragedy, or (in)justice? Our findings demonstrate that global associations could also be explicitly represented and taught. Moreover, they suggest the importance of recognizing that to speak with native fluency within a language, one needs to ``think'' in that language, producing global associations familiar to that language culture.

Our analysis involves several limitations. First, we model language semantics in our analyses exclusively through word co-occurrence information captured through word embedding models. Prior work has demonstrated that estimates of meaning similarity derived from word embeddings are strongly correlated with explicit human judgments of word similarity \cite{hill2015simlex}, but not perfectly correlated, suggesting that our method may not fully capture variability in cross-linguistic semantics. Second, our corpora -- native language expository articles from Wikipedia and second language TOEFL essays -- reveal that there is cross-linguistic variability in connotative semantic associations, but we do not have comparable samples of fiction, poetry, conversation or informal text to directly test this hypothesis. Finally, our data are correlational: behavioral experiments are needed to definitively establish the causal role of semantic space on the cognitive accessibility of semantic associations. % (the alternative hypothesis is that there's a third variable -- ''culture'')

%Second, our corpora include native language expository articles from Wikipedia and second language TOEFL essays, but we do not have comparable samples of fiction, poetry, conversation or informal text that might explicitly follow connotative semantic associations. 

Variability in global semantics has dramatic implications for cross-cultural communication and collaboration. It suggests that faithful, word-by-word translations are not possible, not because the objects of reference are uncertain \cite{quine2013word}, but because associations, metaphors and stories interlink different domains of meanings in one language culture than another \cite{lakoff1987categories}. This means that communication between two people of different language backgrounds will necessarily lead to some loss and distortion of intended meaning. Further, it points to the intriguing possibility that communication will be more faithful among speakers of semantically more aligned languages: A native speaker of Turkish can more effectively communicate in a second language with a native speaker of a semantically similar language, like Japanese, compared to a dissimilar one, like Dutch. Moreover, this suggests the collective cognitive diversity that might emerge from collaboration among those from native languages with very different semantic structures. Understanding the ways in which languages differ in their semantics has the potential to facilitate better cross-cultural communication, and provide a new justification of the importance of cultural difference. Our work is the first to describe the general principles that govern this variability and to characterize these differences across semantic space. 


\matmethods{
\subsection*{Corpora and Models}
 The Second Language TOEFL corpus contained 38,500 short essays written in English by second-language learners of English. Each essay was written in response to one of 28 different essays prompts. The essays were written by equal number of participants from 35 different languages. Each essay was associated with a 1-5 score, implying an essay that ranged from poor to excellent. 

To evaluate whether each language was associated with a distinct semantic space, we trained a single \texttt{doc2vec} model \cite{le2014distributed} on this corpus with the output vector of 200 dimensions and a window size of 6.  We used the gensim implementation of the \texttt{doc2vec} model \cite{rehurek2011gensim}. For each target language, we then sampled 100 essays from each language and estimated the mean cosine distance within all essays in the target language and the mean cosine distance between essays in the target language and essays in other languages. We repeated this procedure 100 times for each language and estimated the mean within and between cosine distance in each language. To quantify the semantic distinctiveness of each language, we calculated the difference (and, alternatively, the ratio, see Fig. S2) of within to between essay distances. This value should exceed zero for differences (or one for ratios) if each language is associated with a distinct semantic space. We report both parametric ($t$-test) and non-parametric (Wilcoxon signed-rank test) analyses of the overall distinctiveness of essays by language, and within-language comparisons of distinctiveness for low versus high scoring essays. All tests are two-tailed.


All remaining analyses were performed on models trained on each language of the 35 languages separately.  Multilingual Wikipedia models were trained on corpora of Wikipedia articles in each of the target native languages using the \texttt{word2vec} skip-gram algorithm with default parameters \cite{bojanowski2016enriching}. The Second Language TOEFL models were trained on 35 corpora separated by the native language of the essay writer using the same training parameters as above (Figs. 1b, 4-5). 


\subsection*{Word level analyses}

The conceptual concreteness of a word was estimated using previously-collected human judgments \cite{brysbaert2014concreteness}. Participants were presented with a single English word, and asked to rate the conceptual concreteness of its meaning on a 5-pt Likert scale, ranging from abstract to concrete.  The notions of concreteness and abstractness were defined for participants as follows: ``Some words refer to things or actions in reality, which you can experience directly through one of the five senses. We call these words concrete words. Other words refer to meanings that cannot be experienced directly but which we know because the meanings can be defined by other words. These are abstract words.'' Judgments were collected for a sample of 39,954 words.

For analyses using the Multilingual Wikipedia Corpus, we translated all words in the concreteness dataset into each of the target 35 languages using the Google Translate API. We selected the set of words that had translations for at least 30 of the languages, and then sampled 1,000 words from each of decile of concreteness (based on the human judgments described above). Of our target sample of words, 45\% of the translations existed in the embedding models across all languages.  For the Second Language TOEFL corpus, we selected all words that were present in the models of 5 or more languages ($N$ = 3,530 words). The words in this sample were roughly uniformly distributed across deciles.  Each word in our sample was rated for concreteness by at least 21 participants (TOEFL:  $M$  $=$ 54.9, $SD$ $=$  398; Wikipedia:  $M$  $=$ 37.5, $SD$ $=$ 236), and there was high agreement across participants in their rating of conceptual concreteness  (TOEFL: Mean $SD$ across words $=$  1.19; Wikipedia:  $SD$ $=$ 1.15).
 
 We compared word sets defined by different levels of concreteness to word sets defined by semantics. For both the Wikipedia and TOEFL models, we used k-means clustering \cite{hartigan1979algorithm} to cluster the words into 10 clusters each based on their semantics, through 50 iterations. To compare groupings by concreteness deciles and semantic clusters, we report in the main text the $\chi^2$ statistic of word counts in a $N$-cluster by concreteness decile matrix  (10 x 10; Fig.\ 1A). We also performed clustering for many other solutions, from 10 to 250 clusters, as shown in Fig.\ 3D, with greater differences between local and global correlations as cluster number grew. In Figure 3D, clusters were determined based on the model trained on English Wikipedia, using word loadings on the 300 Wikipedia embedding dimensions for all pairs of languages. We also created clusters based on the Wikipedia entries for every language in our sample ($N$ = 35).
 
 We next evaluated the semantic similarity of words across languages as a function of word concreteness (Fig.\ 1B). We calculated the pairwise distance (cosine; see methods below) between all words within each concreteness decile. We then calculated the correlation for these word distances for each language pairing ($N$ = 595). Finally, we averaged across language pairs to obtain an estimate of the mean cross-linguistic correlation in word distances across languages for each decile.  Correlation values are Pearson's $r$. 

To characterize cross-linguistic differences in local versus global similarity, we used the same set of words as above to compare  the pairwise cosine distances between words   in different concreteness deciles (``global'') to those in the same concreteness decile (``local'', described above). To measure  global alignment, we calculated the pairwise distance between words in different concreteness deciles, and then calculated the correlation for each language pairing and decile pairing (1-2, 1-3, 1-4, etc.). To measure local alignment, we calculated the pairwise distance between words in the same concreteness deciles, and then calculated the correlation for each language pairing and decile (1-1, 2-2, 3-3, etc.). We then compared the mean local correlation to the mean global correlation across language pairs ($N$ = 595). We report statistics for both parametric (paired $t$-test) and non-parametric (paired Wilcoxon signed-rank test) analyses. 

We conducted a parallel analysis using word sets defined by the semantic clusters (described above) rather than concreteness deciles, varying the number of clusters considered (10 - 250). In this analysis,       ``local'' refers to within-cluster distances and ``global'' refers to across-cluster distances. Means and standard deviations presented for these analyses correspond to the difference in correlation between local and global distances. Effect size measures are Cohen's $d$ and corresponding 95\% confidence interval. 

Finally, we replicated the cluster-based analysis using clusters determined by native language embeddings, rather than English-based clusters (Fig.\ S10). We performed pairwise comparisons of word distances within and across cluster boundaries, calculating this for TOEFL essays in both languages based on the cluster solution from each of the two languages, then averaging. For example, when comparing TOEFL essays from native Hindi and Mandarin speakers, we clustered words covering the Hindi and Chinese Wikipedia entries to capture how each language represents its knowledge base. Then we compared within Hindi-Wikipedia-clusters vs. between Hindi-Wikipedia-clusters for essays from native speakers of both languages; next we compared within Mandarin-Wikipedia-clusters vs. between Mandarin-Wikipedia clusters for the same essays; finally we averaged these differences. This manifests the same pattern of results as those derived from English clusters suggesting the insensitivity of our findings to distinct sources of semantic cluster structure. This, of course, reinforces our finding that local structure is much more similar across languages than global structure.

\subsection*{Semantic similarity in Swadesh words}
We used the Google Translate  API to translate the 22 words analyzed by Youn et al.\ (2016) \cite{swadesh1952lexico} (a subset of the Swadesh list) into each of our target 35 languages.  We included the variants analyzed by Youn et al.\ (e.g., ``day''/``daytime'', ``ash''/``ashes''), averaging across words referring to the same concept. We obtained translations for 96\% of the words across languages using this method. We then used these translations to obtain embedding coordinates for each concept in each language from the Wikipedia-trained embedding model \cite{bojanowski2016enriching}. In cases where translations were available for multiple word forms (e.g., ``day'' and ``daytime'') or the translations were composed of multiple forms, we averaged across vectors.  We  calculated the  pairwise distance (cosine) between each unique word pair (231 pairs)  in each language. Then, for each word, we estimated the correlation (Pearson's $r$) between these distances for  each language pair (595 language pairs). We estimated the physical distance between languages by obtaining the geographical coordinates of each language from Glottolog 2.7 \cite{HammarstroemEtAl2011Oslo} and calculating the geodesic distance (distance on an ellipsoid) between each language pair. Finally, we correlated the language-pairwise distance correlation coefficient with the language-pairwise physical distance metric and estimated $p$-values using the Quadratic Assignment Procedure (QAP) \cite{snapackage}. The QAP procedure estimates $p$-values in a way that accounts for the non-independence of observations (see methods below).

 Climate similarity was based on climate data obtained from WorldClim \cite{fick2017worldclim} on the basis of geographical coordinates from Glottolog 2.7 \cite{HammarstroemEtAl2011Oslo}. For each language pair, we  measured the Euclidean distance between estimates of mean and variance in temperature and precipitation. Measures of linguistic distance were obtained from \cite{dediu2018trees}. Typological distance between languages is based on similarity of 130 typological features for each language coded from the WALS database \cite{wals2013}.  Phonological similarity is based on the Levenshtein edit distance between a standard set of 40 words in each language \cite{wichmann_asjp_2013} (ASJP16). Finally, cultural similarity is based on data from D-place, an ethnographic atlas of cultural traits \cite{kirby2016d,thompson2020cultural}. The cultural distance measure presented in Fig.\ 2c is an aggregate measure of cultural traits from 10 domains (``agriculture and vegetation,'' ``actions and technology, ``emotions and values,'' ``kinship,'' ``law,'' ``possession,'' ``religion and belief,'' ``social and political relations,'' ``the house,'' and ``the physical world.''). See Figure S7b for by-domain analyses. 

%cite this - https://journals.sagepub.com/doi/pdf/10.1177/0142723719892794
\subsection*{Cosine distance as similarity metric}
Similarity and distance between words in an embedding space is typically assessed using ``cosine similarity,'' the cosine of the angle between two word vectors (``cosine distance'' is one minus the cosine between vectors). This is preferred to the Euclidean (straight-line) distance due to properties of high-dimensional spaces that violate intuitions formed in two or three dimensions \cite{kozlowski2019geometry}. For example, as the dimensionality of a hypersphere grows, its volume shrinks relative to its surface area as more of that volume resides near the surface. The surface area of a unit circle surpasses its volume in three dimensions, but as the hypersphere’s dimension approaches infinity, its volume approaches zero. %We normalize all word vectors \cite{levy2015improving},Levy, Goldberg, and Dagan 2015) such that they lie on the surface of a hypersphere of same dimensionality as the space.

A geometric interpretation may be preferable to a probability one like the Kulback-Leibler Divergence or Wasserstein Distance because the distance between two probability distributions assumes independence and equal weight between each dimension, which is not the case for neural models like \texttt{word2vec} that approximate factorization of a (very) large matrix, with a monotonically decreasing influence of each dimension in describing the overall variation of the matrix \cite{levy2014neural}. 

\subsection*{QAP non-independence}
Multiple regression quadratic assignment procedures (MR-QAP) tests are permutation tests for multiple linear regression model coefficients for data organized in square matrices of relatedness among $n$ objects \cite{dekker2007sensitivity}. This data structure has been most common in studies of social networks, where variables indicate a relation between $n$ actors, but are equally applicable here, where we explore a distance relationship between $n$ languages. In both network, and distance cases, the rows and columns are explicitly not independent of one another, and so assumptions of identically and independently distributed data, required for linear regression are misplaced. MR-QAP permutation tests allow us to demonstrate that the autocorrelation among language pairs does not influence the regressed association that we find--that the distances between clusters is significantly more variable than the distances within clusters (e.g., the alpha estimated in the regression of global distances on local distances is significantly greater than 0.) It is common to have coefficients that look highly significant under a classical null hypothesis test and that remain insignificant under MR-QAP because the QAP null hypothesis accounts for autocorrelation. 

}

\showmatmethods{} % Display the Materials and Methods section

\acknow{We would like to thank the National Science Foundation \#1520074 to the University of Chicago for partial funding for this project.}

\showacknow{} % Display the acknowledgments section

% Bibliography
\bibliography{L2ETS_bib.bib}

\end{document}
