{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2ETS Study 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save data from ETS as feathers so can explore in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and save gensim model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.0\n"
     ]
    }
   ],
   "source": [
    "import gensim \n",
    "import gensim.models as g\n",
    "print(gensim.__version__)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import feather as f\n",
    "import pickle\n",
    "#import feather-format\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = g.Doc2Vec.load(\"../../data/raw/models/all.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 38500 essays with vectors of length 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nshape=\" + str(mod.docvecs.doctag_syn0.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save doc vector indices so can merge with meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_doct_tags = pd.DataFrame()\n",
    "doctag_ids_for_R = all_doct_tags.from_dict(mod.docvecs.doctags).T\n",
    "doctag_ids_for_R.columns = ['offset', 'word_count', 'doc_count']\n",
    "doctag_ids_for_R.index.name = 'essay_id'\n",
    "doctag_ids_for_R.reset_index(inplace = True)\n",
    "f.write_dataframe(doctag_ids_for_R, \"../../data/doctag_indices_all_model.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save doc vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docvecs_for_R = pd.DataFrame(mod.docvecs.doctag_syn0)\n",
    "f.write_dataframe(docvecs_for_R, \"../../data/docvecs_all_model.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docvecs_for_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do the same thing as above, but as loop..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory_string = \"../../data/raw/models/L1_high_low_models/\"\n",
    "directory_string = \"../../data/raw/models/random/\"\n",
    "directory = os.fsencode(directory_string)\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    print(filename)\n",
    "    \n",
    "    mod = g.Doc2Vec.load(directory_string+filename)\n",
    "    print(\"\\nshape=\" + str(mod.docvecs.doctag_syn0.shape))\n",
    "    \n",
    "    all_doct_tags = pd.DataFrame()\n",
    "    doctag_ids_for_R = all_doct_tags.from_dict(mod.docvecs.doctags).T\n",
    "    doctag_ids_for_R.columns = ['offset', 'word_count', 'doc_count']\n",
    "    doctag_ids_for_R.index.name = 'essay_id'\n",
    "    doctag_ids_for_R.reset_index(inplace = True)\n",
    "    #f.write_dataframe(doctag_ids_for_R, \"../../data/processed/L1_high_low_models/doctag_indices_\" + filename + \".feather\")\n",
    "    #f.write_dataframe(doctag_ids_for_R, \"../../data/processed/L1_models/doctag_indices_\" + filename + \".feather\")\n",
    "\n",
    "    docvecs_for_R = pd.DataFrame(mod.docvecs.doctag_syn0)\n",
    "    #f.write_dataframe(docvecs_for_R,\"../../data/processed/L1_high_low_models/docvecs_\" + filename + \".feather\")\n",
    "    #f.write_dataframe(docvecs_for_R,\"../../data/processed/L1_models/docvecs_\" + filename + \".feather\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save mapping of essay ids to low vs. high group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_string = \"../../data/raw/models/L1_models/\"\n",
    "directory = os.fsencode(directory_string)\n",
    "\n",
    "essay_group_mappings = pd.DataFrame()\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    print(filename)\n",
    "    mod = g.Doc2Vec.load(directory_string+filename)\n",
    "    print(\"\\nshape=\" + str(mod.docvecs.doctag_syn0.shape))\n",
    "\n",
    "    all_doct_tags = pd.DataFrame()\n",
    "    doctag_ids_for_R = all_doct_tags.from_dict(mod.docvecs.doctags).T\n",
    "    doctag_ids_for_R.columns = ['offset', 'word_count', 'doc_count']\n",
    "    doctag_ids_for_R.index.name = 'essay_id'\n",
    "    doctag_ids_for_R.reset_index(inplace = True)\n",
    "    doctag_ids_for_R['group'] = \"low_\" + filename[0:3]\n",
    "\n",
    "    # append to dataframe\n",
    "    essay_group_mappings = pd.concat([essay_group_mappings, doctag_ids_for_R])\n",
    "\n",
    "# write dataframe for this language pair\n",
    "f.write_dataframe(essay_group_mappings, \"/Users/mollylewis/Documents/research/Projects/L2ETS/studies/study2/data/processed/models/low_essay_mappings.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are  24713 words with 200-D vectors. (all model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.wv.syn0.size/200, len(mod.wv.index2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write word vecs to feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvecs_for_R = pd.DataFrame(mod.wv.syn0)\n",
    "f.write_dataframe(wordvecs_for_R, \"../../data/processed/models/all_model/wordvecs_all_model.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write word vec words to feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = pd.DataFrame(mod.wv.index2word)\n",
    "f.write_dataframe(all_words, \"../../data/processed/models/all_model/words_all_model.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now do this in a loop.... (for L1 models and low/high L1 models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directory_string = \"../../data/raw/models/L1_high_low_models/\"\n",
    "directory_string = \"../../data/raw/models/L1_models/\"\n",
    "directory = os.fsencode(directory_string)\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    filename = os.fsdecode(file)\n",
    "    print(filename)\n",
    "    \n",
    "    mod = g.Doc2Vec.load(directory_string+filename)\n",
    "    \n",
    "    wordvecs_for_R = pd.DataFrame(mod.wv.syn0)\n",
    "    #f.write_dataframe(wordvecs_for_R, \"../../data/processed/models/L1_high_low_models/wordvecs_\" + filename + \".feather\")   \n",
    "    f.write_dataframe(wordvecs_for_R, \"../../data/processed/models/L1_models/wordvecs_\" + filename + \".feather\")   \n",
    "    \n",
    "    all_words = pd.DataFrame(mod.wv.index2word)\n",
    "    #f.write_dataframe(all_words, \"../../data/processed/models/L1_high_low_models/words_\" + filename + \".feather\")\n",
    "    f.write_dataframe(all_words, \"../../data/processed/models/L1_models/words_\" + filename + \".feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = pd.read_pickle(open(\"../../data/raw/essay_word_counts.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wc.keys()\n",
    "ec = []\n",
    "for key in wc:\n",
    "    df = wc[key]\n",
    "    df[\"essay_id\"] = key\n",
    "    ec.append(df)\n",
    "\n",
    "ec_df = pd.concat(ec)\n",
    "feather.write_dataframe(ec_df, 'essay_word_counts.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
